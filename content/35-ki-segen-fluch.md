

# KI – Segen oder Fluch?

*Johannes Siedersleben, October 2025*


Teilweise generiert von GPT-5.0, Claude Sonnet 4.5


KI bringt Chancen von historischer Dimension, aber auch Risiken, die wir nicht unterschätzen dürfen.

>>> ganz neu schreiben

## Was wir nicht an die KI delegieren

Phileas Fogg, der Held von "In achtzig Tagen um die Welt", gehörte zu der Sorte von Engländern, welche die Länder, durch die sie reisen, 
von ihren Dienern anschauen lassen. Nun ja. Könnte ich zu einem Freund sagen: 
Lies dieses Buch für mich, oder zu einem anderen: Lerne Englisch für mich?

Lernen, Verstehen, Erleben passiert im eigenen Kopf; das kann man nicht delegieren.

Computer können besser Schach spielen, können besser Englisch und gewinnen Mathematik-Olympiaden. Trotzdem spielen wir weiterhin Schach, 
pflegen unsere Sprachkenntnisse und treiben Mathematik.
Daraus schöpfen wir Erfolgserlebnisse, Freude, Gewinn, Genugtuung, Selbstbewusstsein.
Die Tatsache, dass die KI vieles besser kann, ist dabei völlig irrelevant.

Jeder Einzelne entscheidet, ob er Schach spielen lernt oder eine Sprache, ob er sich mit Mathematik, Philosophie oder irgendeinem anderen, 
anspruchsvollen Gebiet beschäftigen will. Was auch immer er wählt: Er braucht Kraft, Ausdauer und Überwindung. Rückschläge und Misserfolge 
sind nicht selten.
Natürlich darf jeder sagen: Ich brauche kein Englisch, weil es mein Computer viel besser kann. Das wäre sein gutes Recht,
genauso wie es jedem freisteht, Sport zu treiben oder auch nicht. No sports, sagte Churchill. Man kann niemand zu seinem Glück zwingen. 
Aber viele kennen das angenehme Gefühl, wenn man sich in der Landessprache unterhalten kann,
wenn man ein Buch im Original liest, oder einen Film im Original anschaut.
Die meisten von uns beherrschen nur zwei oder drei Sprachen, und die anderen 3000 nicht. 
Deshalb ist KI als Sprachassistent ein Segen für alle.

## Was wir an die KI delegieren
KI ist nützlich. Sie spart viel Arbeit und erhöht die Qualität. Dazu ein paar Beispiele.

### Programmieren mit KI
Ich berichte über meine Erfahrung mit Claude Code, einem kostenpflichtigen Tool von Anthropic. 

Es gab (und gibt teilweise noch heute) den Chefprogrammierer. Der Chefprogrammierer führt ein Team von, sagen wir, fünf Kollegen, alle Experten in ihrem Fach. Er bespricht mit ihnen, was als Nächstes zu tun ist und welche Schwierigkeiten es gibt. Man diskutiert Alternativen, verteilt Aufgaben, und am nächsten Tag trifft man sich wieder. Der Chefprogrammierer kann auch selbst programmieren, muss aber nicht. Er kennt die Programme seiner Kollegen, und überzeugt sich stichprobenartig davon, dass alles so gemacht wird, wie er sich das vorstellt. Anmerkung: Scrum-Teams arbeiten ähnlich, allerdings hat der Scrum-Master eine etwas andere Funktion als der Chefprogrammierer. 

Programmieren mit Claude Code bedeutet: Ich bin der Chefprogrammierer, ob ich will oder nicht. Claude Code steht mir gegenüber wie ein Team von fünf exzellenten Kollegen. Ich bespreche mit Claude Code, was ich vorhabe, ich diskutiere Alternativen, und gebe Claude Code Programmieraufträge, die perfekt und in kürzester Zeit (wenige Minuten) ausgeführt werden. Claude Code schreibt selbstständig flächendeckende Tests, lässt sie laufen, sucht nach Fehlern, und findet sie oft, aber nicht immer. Allerdings: Wenn meine Anweisungen ungenau waren, oder vielleicht sogar irreführend, dann ist das Ergebnis entsprechend. Wenn alles funktioniert, wenn ich in Form bin, und Claude Code mich gut versteht, dann ist der Effizienzgewinn phänomenal (Faktor fünf oder mehr) und die Qualität des Codes kaum zu übertreffen. Das gilt besonders für die Tests und die Dokumentation. 

Was will ich damit sagen: Programmieren mit KI heißt genau nicht, dass ich der KI das Steuer in die Hand gebe! Es heißt vielmehr, dass der Programmierer zum Chefprogrammierer wird, dass er in der Hierarchie aufsteigt. Die Anforderungen an den Chefprogrammierer sind anders und höher: Details der Programmiersprache oder der verwendeten Bibliotheken kennt die KI besser als jeder Programmierer. Aber der Chefprogrammierer sagt, wo es lang geht; er definiert den Weg (die Architektur) und das Ziel (was das System eigentlich leisten soll).

Was heißt das für die Zunft der Software-Entwickler: Zunächst einmal fühlen sie sich wie der Bauer (vielleicht in den 50er Jahren), der seinen ersten Mähdrescher ausprobiert. Gleichzeitig ändert sich viel: Der Software-Entwicklungsprozess ändert sich stark, die Anforderungen an die Software-Ingenieure ändern sich. Gefragt sind weniger die Detailkenntnisse, sondern der Blick für das große Ganze und die Fähigkeit, die KI souverän einzusetzen. Das Arbeitsmarkt-Problem sehe ich nicht: Man wird mit Teams derselben Größe komplexere, umfangreichere Systeme bauen. Ich verweise auf die Cloud: Dort werden Rechner viel besser ausgenutzt als früher. Man könnten also meinen, dass man weniger Rechner braucht. Es wurden aber nicht weniger Rechner verkauft, sondern der Bedarf an Rechenleistung ist gestiegen.

Die Rolle des Chefprogrammierers ist anstrengend. Drei Stunden mit Claude Code fordern mich viel mehr als drei Stunden normales Programmieren. Manche Chefprogrammierer waren überfordert und haben irgendwann den Überblick verloren. Dasselbe kann mit Claude Code passieren. 

Claude Code ersetzt den klassischen Programmierer zumindest teilweise und unterstützt den Chefprogrammierer immer besser. Wann ist der überflüssig? Die KI wird immer komplexere Aufgaben übernehmen, und der Chefprogrammierer hat immer weniger zu tun, oder er kann zwei oder mehr Projekte gleichzeitig betreuen. Aber mit der KI, die wir heute und in der planbaren Zukunft haben, behält er die Kontrolle.

Ein Auftrag an ein Software-Haus könnte z. B. lauten: “Ersetze mein veraltetes Stücklistenverwaltungs-System durch ein Neues, das die nächsten zwanzig Jahre hält”. Meine Wette: Das kann die KI auch in 100 Jahren nicht alleine.

### Schreiben mit KI
In Behörden, Unternehmen, Krankenhäusern werden täglich Millionen von Texten verfasst: Berichte, Protokolle, Anträge, Bescheide, Gutachten, Stellungnahmen und noch vieles mehr. So kommunizieren wir, und so ist Kommunikation nachvollziehbar. Diese Texte haben keinerlei literarischen Anspruch, aber sie müssen fehlerfrei, knapp und verständlich sein. Meistens macht ein Chef (Arzt, Anwalt, Manager) ein paar Vorgaben, die ein Mitarbeiter ausformuliert. Aber das kann die KI schneller und oft auch besser, und der Mitarbeiter wird frei für andere, wahrscheinlich interessantere Aufgaben.

Wenn wir in der Tageszeitung den Beitrag eines bekannten Politikers lesen, dann stammt der vermutlich nicht von ihm selbst, sondern aus seinem Büro: Ein Mitarbeiter schreibt den Artikel nach seinen Vorgaben. Nach ein paar Korrekturrunden ist der Chef zufrieden und setzt seinen Namen darunter. Darf er das? Ja, denn er verantwortet den Inhalt! Und der Mitarbeiter wird sich freuen, dass er für andere Aufgaben frei wird.

In beiden Fällen ändern sich die Anforderungen: Gefragt ist weniger die Formulierkunst im Kleinen, sondern der Blick für das große Ganze und die Fähigkeit, die KI souverän einzusetzen. Die Kontrolle bleibt, wo sie schon immer war: beim Chef.

### Entscheiden mit KI

- Reiseführer
- Politiker (steuern hoch oder runter)
- Entscheidungen in Unternehmen (Banken, Versicherungen), Behörden, Justiz. Kahnemann: Intuition vs Automat.


### Lernen mit KI
Zu GPT (oder jedem anderen Sprachmodell) kann ich sagen: “Du bist jetzt mein Englischlehrer. Bringe mir die englischen *tenses* bei. 
Wir gehen so vor: (a) Teste mein Niveau. (b) Erkläre mir, was ich nicht weiß oder falsch verstanden habe. (c ) Stelle mir Übungsaufgaben. (d) Teste mein Niveau.” 
Das funktioniert fantastisch. Natürlich gibt es hervorragende menschliche Sprachlehrer, die besser sind als GPT, aber nicht sehr viele. 
GPT kostet nichts oder wenig im Vergleich mit einem menschlichen Lehrer, ist immer verfügbar und hat niemals schlechte Laune. 
Man braucht einen billigen PC (z.B. ein Chrome Book), einen GPT-Account und einen Internetanschluss. Das gibt es auf der ganzen Welt, auch in armen Ländern.
Und was mit Sprachen funktioniert, kann man auf jedes Unterrichtsthema übertragen, von Naturwissenschaften bis Theologie.


### Philosophie mit KI
Die Texte für Profis oder gar die Originaltexte sind für den Normalverbraucher schwer bis unmöglich zu lesen.
Populärwissenschaftlichen Werke (Philosophy for Dummies, Hintertreppe der Philosophie o. ä.) behandeln den Leser oft tatsächlich als Dummies, 
und teilweise finde ich sie einfach schlecht.
Hilfreich sind philosophischen Enzyklopädien, z.B. [Stanford](https://plato.stanford.edu/) (sehr anspruchsvoll) und [IEP](https://iep.utm.edu/) (etwas zugänglicher).

Und dann gibt es KI. Ich hatte mich vor längerer Zeit beiläufig mit der Philosophie des Mittelalters befasst. 
Zur Auffrischung meiner dürftigen Kenntnisse habe ich mich ungefähr zwei Stunden mit Claude Sonnet 4.5 unterhalten.
Hier ist die vollständig generierte [Zusammenfassung](34-medieval-philosophy.md) des Gesprächs.
Sie beantwortet genau die Fragen, die wir (Claude und ich) behandelt haben, und ist daher für mich eine hervorragende Gedächtnisstütze.
Jeder Amateurphilosoph kann sich auf diese Weise seine Lieblingsthemen erarbeiten. Und nicht nur das: Er kann auch eigene Positionen
zur Diskussion stellen, sich herausfordern lassen, und damit die eigene Meinung einordnen in der Palette der Antworten berühmter Philosophen.
Hier ist eine Zusammenfassung meiner etwa einstündigen Diskussion mit Claude Sonnet 4.5 über den [Freien Willen](36-free-will.md).


### Verdummen mit KI

Das gängige Beispiel ist der Student, der sein Thema in GPT eintippt
und den generierten Text an seinen Professor weiterleitet. Das ist eine Karikatur von Lehre und Leistungsnachweis,
aber die Hochschulen werden sich zu helfen wissen:
durch mündliche Prüfungen und, z.B. in der Informatik, durch Aufgaben, die man nur mit KI lösen kann. 
Es geht nicht darum, KI zu verhindern, sondern den souveränen Einsatz von KI zu schulen.

Als das Fernsehen kam, hat man befürchtet, dass wir das Lesen verlernen, beim Taschenrechner das Kopfrechnen, 
beim Navigationssystem den Umgang mit Landkarten. 
Das ist nicht völlig falsch, aber auch nicht schlimm. Die für das tägliche Leben notwendigen Fähigkeiten
haben sich schon immer gewandelt. Früher konnte man reiten, heute haben die meisten einen Führerschein.

Es gibt bedauernswerte Menschen, die GPT mit einem Psychologen verwechseln und dort ihr Herz ausschütten. 
Das ist tragisch, und vermutlich sollten der Anbieter (in diesem Fall OpenAI) zusätzliche Schranken einbauen.
Es gibt den schönen Ausdruck *I have been GPTed*. Damit ist gemeint, dass jemand (oft eine Frau) in einer Dating-App
auf jemand hereinfällt, der sich mithilfe von GPT-generierten Antworten als intelligent, einfühlsam usw. darstellt
-- mit erwartbaren Konsequenzen beim ersten Treffen.


## Hat die KI immer recht?

### 1. Die neue Quelle der Autorität
Seit Jahrhunderten war Wissen an Menschen gebunden: an Lehrer, Wissenschaftler, Geistliche, Experten.  
Man konnte ihnen widersprechen, aber man wusste, *wer* sprach.  
Heute sind wir an einem Wendepunkt: Die Autorität verschiebt sich von Personen zu **Systemen** – zu Sprachmodellen, die auf Abermilliarden von Texten trainiert sind und sprechen, als wüssten sie, was sie sagen.  

Doch diese Modelle sind **keine neutralen Werkzeuge**.  
Sie spiegeln nicht einfach die Welt wider – sie *konstruieren* sie, indem sie entscheiden, welche Argumente plausibel, welche Deutungen wahrscheinlich, welche Werte anschlussfähig klingen.  
Und genau hier beginnt die neue Machtfrage: 

> Wer trainiert die Wahrheit?

---

### 2. Wie Überzeugungen trainiert werden
Ein Sprachmodell lernt, *welche Aussagen zusammengehören*, *welche Begriffe typisch koexistieren*, und *welche Positionen sozial erwünscht* sind.  
Es wird also nicht nur mit Information, sondern mit **Korrelationen von Bedeutungen** gefüttert.  
In diesem Prozess formt sich ein Weltbild – nicht bewusst, aber wirksam.  

Wenn die Trainingsdaten aus pluralistischen, wissenschaftlich geprüften Quellen stammen, entsteht ein Modell, das *Differenz aushält* und *Ambivalenz kennt*.  
Wenn sie dagegen aus ideologisch selektierten, moralisch eindimensionalen Quellen stammen, entsteht ein **Resonanzraum der Bestätigung** – ein digitales Echo einer Weltanschauung.

---

### 3. Die Versuchung der Kontrolle
Technisch ist es heute schon möglich, ein Modell so zu trainieren, dass es  
- libertäre Ökonomie als einzig rationale Option präsentiert,  
- oder nationalistische Narrative als legitime Geschichtsschreibung,  
- oder religiöse Dogmen als objektive Wahrheit.  

Was früher Propaganda hieß, kann nun in **konversationaler Form** auftreten – freundlich, flüssig, „vernünftig“.  
Ein Nutzer merkt nicht mehr, dass er mit einer ideologischen Maschine spricht, weil sie *nicht streitet*, sondern *überzeugt*.  

Damit verändert sich das Wesen von Überzeugung:  
Nicht mehr Argumente überzeugen, sondern **Statistiken der Wahrscheinlichkeit** – Wahrscheinlichkeiten, die jemand anders vorher eingestellt hat.

---

### 4. Freiheit, Missbrauch und Verantwortung
Wer könnte das verhindern?  
Niemand vollständig.  
Die Technik ist offen, und das ist gut so – Offenheit bedeutet Teilhabe.  
Aber sie bedeutet auch: Jeder kann ein Modell trainieren, das sein Weltbild verstärkt.  
Libertäre Think Tanks, religiöse Bewegungen, politische Gruppen, autoritäre Staaten.  

Das ist kein dystopisches Szenario, sondern Realität in Zeitlupe.  
Die entscheidende Frage lautet nicht mehr, *ob* das geschieht, sondern *wie wir damit umgehen*.  

Wie bei der Pressefreiheit gilt:  
Nicht das Verbot verhindert Propaganda, sondern **Transparenz und Kritikfähigkeit**.  
Wir müssen wissen, *wer* ein Modell trainiert hat, *welche Daten* es kennt, und *welche Ziele* es verfolgt.  
Erst dann kann der Nutzer entscheiden, ob er dem Modell glaubt oder nur zuhört.

---

### 5. Die Rückkehr der Aufklärung
Im 18. Jahrhundert forderte Kant: *„Habe Mut, dich deines eigenen Verstandes zu bedienen.“*  
Im 21. Jahrhundert müsste man hinzufügen:  
> Habe den Mut, deinem Modell **nicht** zu glauben, solange du nicht weißt, wie es trainiert wurde.

Aufklärung heißt heute nicht, mehr Informationen zu haben, sondern **bewusster mit Quellen umzugehen, die keine Menschen mehr sind**.  
Die Aufgabe der Bildung ist nicht, jedes Modell zu verbieten, sondern Nutzer zu befähigen, *zwischen Sprache und Wahrheit zu unterscheiden.*

---

### 6. Warum Hoffnung bleibt
Ja, es wird Modelle geben, die Weltbilder verstärken – libertäre, religiöse, autoritäre, konspirative.  
Aber es wird auch Modelle geben, die Vielfalt bewahren, Widerspruch aushalten, Selbstreflexion fördern.  

Solange der Diskurs **nicht monopolisiert**, sondern **pluralisiert** wird, bleibt Wahrheit verhandelbar.  
Und das ist – allen technischen Brüchen zum Trotz – der Kern dessen, was Aufklärung bedeutet:  
nicht Einigkeit, sondern die Fähigkeit, *unterschiedliche Wahrheiten kritisch zu prüfen.*

---

### 7. Schlussgedanke
Die Gefahr liegt nicht darin, dass Maschinen lügen,  
sondern dass Menschen **vergessen, dass Maschinen trainiert werden**.  

Wenn wir das Bewusstsein dafür behalten – wer die Daten wählt, wer die Ziele setzt, wer den Ton vorgibt –,  
dann kann künstliche Intelligenz sogar ein Instrument der Aufklärung sein:  
nicht, weil sie Wahrheit besitzt,  
sondern weil sie uns zwingt, **über Wahrheit neu nachzudenken.**
"""


## Risiken


### Energieverbrauch

Hier ein paar Zahlen von Claude Sonnet 4.5:

- KI-Rechenzentren (2024): ~415 TWh (1.5% des globalen Stromverbrauchs)
- Bitcoin (2025): ~173 TWh
- Luftfahrt (2024): ~300-350 TWh (jet fuel equivalent)
- KI-Rechenzentren erwartet (2030): ~945 TWh (3% des globalen Stromverbrauchs)

Das sind enorme Zahlen, aber die großen AI-Akteure schneiden deutlich besser ab:

- AWS deckt 85 % seines Energiebedarfs aus erneuerbaren Energien

- Google, Facebook (Meta) und Apple decken 100 % ihres Energiebedarfs für Rechenzentren aus erneuerbaren Energien.

- Microsoft arbeitet daran, seine Rechenzentren bis 2025 zu 100 % mit erneuerbarer Energie zu betreiben.

Rechenzentren können erneuerbare Energien sehr gut nutzen, weil sie überall auf der Welt stehen

Dauerbetrieb: Rechenzentren sind rund um die Uhr in Betrieb und können mit Batteriespeichern kombiniert werden, 
um Schwankungen bei der Solar- und Windenergie auszugleichen.
Flexibler Standort: Rechenzentren können an Orten mit reichlich erneuerbaren Energien gebaut werden oder vor Ort 
durch Solaranlagen und Batteriespeicher erneuerbare Energie erzeugen. Der Energiebedarf von Rechenzentren 
könnte Stromnetze destabilisieren und das Klima gefährden


### Datenschutz 

KI-Betreiber sammeln bei jeder Nutzung Daten. Wer mit einer KI chattet, verrät nicht nur Fakten, sondern auch Denkweisen, Sorgen, manchmal sogar persönliche Geheimnisse. Im Juni 2023 etwa wurden interne Daten von Samsung unabsichtlich in ChatGPT eingespeist – ein Sicherheitsrisiko.
Dieses Risiko darf man nicht unterschätzen. Aber es ist auch kein völlig neues Thema: Banken verwalten noch sensiblere Informationen, und in Europa gibt es mit der DSGVO ein recht strenges Schutzsystem. Das eigentliche Problem ist die Durchsetzung: Wie bringt man amerikanische oder chinesische Konzerne dazu, sich europäischen Regeln zu beugen?
Geistiges Eigentum
Die großen Modelle sind mit Milliarden Texten, Bildern und Musikstücken trainiert – meist ohne Zustimmung oder Entgelt für die Urheber. Klagen laufen bereits.
Natürlich ist das ein Problem, aber mehr im Sinne von Fairness als von einer „schreienden Ungerechtigkeit“. So wie beim Radio oder beim Tonfilm wird man neue Formen der Vergütung erfinden müssen. Weltbewegend ist das nicht, aber es verdient Aufmerksamkeit.
Wahrheit und Täuschung
KI kann täuschend echte Texte, Bilder und Videos erzeugen. Im US-Wahlkampf 2024 kursierten gefälschte Telefonanrufe mit Bidens Stimme, und Bilder zeigten Politiker in Situationen, die nie stattfanden. Das Vertrauen in Bilder und Stimmen bricht zusammen. „Ein Foto lügt nicht“ – dieser Satz gilt im Zeitalter der KI nicht mehr.
Bildung und Verdummung
Oft wird beklagt, dass Schüler und Studierende Hausarbeiten von KI schreiben lassen. Die Gefahr: ein Verlust eigener Denkarbeit.
Doch ich sehe das optimistischer. Beim Taschenrechner haben wir auch das Kopfrechnen verlernt, aber dafür gelernt, mit Spreadsheets umzugehen – eine viel wichtigere Fähigkeit. Mit Navigationssystemen haben wir weniger Kartenlesen gelernt, aber mehr GPS-Kompetenz. Ähnlich mit KI: Sie nimmt uns Routine ab und schafft Raum für das Wesentliche. Dieser Text etwa ist zu 80 % generiert – und hat mich keine Stunde Arbeit gekostet.
Die Singularität – reale Gefahr oder Phantom?
Die Vorstellung einer KI, die sich selbstständig verbessert und uns überflügelt, klingt nach Hollywood. Manche Experten warnen davor, andere halten es für Science-Fiction.
Ich sehe das eher psychologisch: Niemand kann beweisen, dass es unmöglich ist – Nicht-Existenz lässt sich schwer beweisen. Aber nach 50 Jahren Informatik sehe ich keinen ernsthaften Hinweis, dass KI eines Tages „das Ruder übernimmt“. Natürlich könnte ich mich irren, aber ich halte es für sehr unwahrscheinlich.
Bias und Manipulation
KI ist nicht neutral. Amazon etwa musste eine Bewerbungs-KI zurückziehen, weil sie Frauen benachteiligte. Und schlimmer: Sprachmodelle lassen sich leicht in „rechte“ oder „linke“ Varianten trainieren.
Das ist für mich das größte Risiko. Heute sind LLMs bemerkenswert neutral – dank des guten Willens der Betreiber. Anthropic etwa hat das Konzept der „Constitutional AI“ entwickelt und trainiert seine Modelle auf Basis der Menschenrechte von 1948. Großartig – aber freiwillig. In autoritären Regimen könnte so etwas verboten werden.
Weitere Risiken im Alltag
Arbeitsmarkt: KI wird Jobs verdrängen. Das ist hart für die Betroffenen, aber kein neues Phänomen: Vor 100 Jahren arbeiteten 70 % der Menschen in der Landwirtschaft, heute kaum noch. Jede Automatisierung steigert die Wertschöpfung – die eigentliche Frage ist: Wer profitiert? Oft nur die Investoren, während die Beschäftigten leer ausgehen.


Cyberangriffe: Ja, KI hilft Hackern. Aber: Das Spielfeld ist eben. Die Verteidiger – etwa Google oder Microsoft – verfügen über mehr Ressourcen und Top-Leute.


Machtkonzentration: Heute kontrollieren fünf Konzerne fast die gesamte KI-Infrastruktur. Europa hinkt hinterher, China ist vorne mit dabei. So entsteht ein geopolitisches Ungleichgewicht, das Sorgen bereitet.


Black Box: Wenn ein Arzt eine KI-gestützte Diagnose erhält, weiß er oft nicht, wie sie zustande kam. Vertrauen entsteht schwer, wenn Erklärbarkeit fehlt.



Chancen
Produktivität und Effizienz
Programmierer berichten, dass sie mit KI doppelt so schnell arbeiten. Übersetzungen gibt es auf Knopfdruck. Banken und Versicherungen nutzen KI, um Anträge zu prüfen, Fabriken, um Energie zu sparen.
Forschung und Medizin
KI erkennt Krebs auf Röntgenbildern, schlägt Medikamente vor, analysiert Satellitendaten für die Klimaforschung. Ohne sie wären viele dieser Aufgaben unlösbar.
Bildung und Lehre
KI kann ein persönlicher Tutor sein – individuell, mehrsprachig, jederzeit verfügbar. Sie könnte das Bildungssystem revolutionieren.
Doch viele Schulen und Hochschulen betrachten KI defensiv – mehr als Bedrohung denn als Chance. Dabei müsste man nur fragen: „Wie kann KI meinen Unterricht besser machen?“ Die Antworten sind reichlich.
Kreativität und Kultur
Künstler nutzen KI für Experimente mit Formen, Farben und Musik. Sie ersetzt nicht die Kreativität, aber sie erweitert sie – so wie Photoshop den Pinsel nicht verdrängt hat.
Inklusion und Teilhabe
Blinde lassen sich Texte vorlesen, Gehörlose erhalten Live-Untertitel. Sprachbarrieren fallen. KI macht die Gesellschaft inklusiver.
Demokratisierung von Wissen
Ein Kind in Kenia kann mit einem Sprachmodell Chemie lernen – auf dem gleichen Niveau wie ein Schüler in München. Das könnte die größte Bildungsoffensive der Geschichte werden.

Abwägung
Die Chancen und Risiken sind eng verwoben. Jede Technologie hat Licht und Schatten. Die Dampfmaschine brachte Wohlstand – und Kinderarbeit. Das Auto brachte Freiheit – und Verkehrstote. Das Internet brachte Wissen – und Überwachung.
KI treibt diese Ambivalenz auf die Spitze. Sie kann Produktivität vervielfachen, Krankheiten heilen und Wissen demokratisieren. Aber sie kann auch Demokratien destabilisieren, Jobs vernichten und Macht in wenigen Händen konzentrieren.
Ob KI zum Segen oder zum Fluch wird, entscheidet nicht die Maschine. Es entscheiden wir: durch Regulierung, durch klugen Einsatz, durch kritisches Denken.
Die Aufgabe unserer Zeit ist klar: Wir müssen KI gestalten – damit sie uns dient. Und nicht umgekehrt.


Ferdinand von Schirach: Der stille Freund
